{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztm3le7L8vTk",
        "outputId": "662ed198-0c3c-4412-f717-7a829a5cb344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'RadImageNet'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 68 (delta 31), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (68/68), 38.44 KiB | 7.69 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/Navya003/RadImageNet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc5829MMFJnp",
        "outputId": "8a1b917e-6db8-4ce1-c274-85d31ac5b97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RadImageNet\n"
          ]
        }
      ],
      "source": [
        "%cd /content/RadImageNet/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkhQL0t2FO_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50955496-42b2-4109-9a10-3180c3d1cffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn numpy pandas opencv-python matplotlib openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2CJuZquFXHy",
        "outputId": "78183c39-0b62-4e56-b96c-e49df154f2c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-07 06:59:55.795048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762498795.826487    1674 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762498795.835623    1674 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762498795.857961    1674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762498795.857995    1674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762498795.858005    1674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762498795.858012    1674 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-07 06:59:55.864680: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Starting Fashion-MNIST conversion to: fashion_mnist_full_dataset\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Processing training data...\n",
            "  Saved 10000 training images.\n",
            "  Saved 20000 training images.\n",
            "  Saved 30000 training images.\n",
            "  Saved 40000 training images.\n",
            "  Saved 50000 training images.\n",
            "  Saved 60000 training images.\n",
            "Finished saving 60000 training images.\n",
            "Processing test data...\n",
            "  Saved 2000 test images.\n",
            "  Saved 4000 test images.\n",
            "  Saved 6000 test images.\n",
            "  Saved 8000 test images.\n",
            "  Saved 10000 test images.\n",
            "Finished saving 10000 test images.\n",
            "Fashion-MNIST conversion complete. Data saved to 'fashion_mnist_full_dataset'\n"
          ]
        }
      ],
      "source": [
        "!python convert_fashion_mnist_full.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STPtFl1wFb3S",
        "outputId": "9d87df69-a6a1-41a2-b51a-690987a427be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-04 06:30:08.082162: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762237808.101077    1020 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762237808.106832    1020 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762237808.121462    1020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762237808.121487    1020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762237808.121491    1020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762237808.121494    1020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-04 06:30:08.125841: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2.19.0\n",
            "Number of GPUs available: 1\n",
            "Loading training data paths and labels...\n",
            "DataLoader (train): Found categories in directory: ['Coat', 'Sandal', 'T-shirt', 'Bag', 'Sneaker', 'Dress', 'Ankle boot', 'Pullover', 'Shirt', 'Trouser']\n",
            "DataLoader (train): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/train/Coat\n",
            "DataLoader (train): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/train/Sandal\n",
            "DataLoader (train): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/T-shirt\n",
            "DataLoader (train): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/train/Bag\n",
            "DataLoader (train): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/train/Sneaker\n",
            "DataLoader (train): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/train/Dress\n",
            "DataLoader (train): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/train/Ankle boot\n",
            "DataLoader (train): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/train/Pullover\n",
            "DataLoader (train): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/Shirt\n",
            "DataLoader (train): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/train/Trouser\n",
            "DataLoader (train): Total images found: 60000\n",
            "DataLoader (train): Total labels found: 60000\n",
            "DataLoader (train): Number of unique labels after encoding: 10\n",
            "Training data: 60000 images, 10 classes\n",
            "Building Model ....\n",
            "I0000 00:00:1762237817.037818    1020 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "Training and cross-validating model...\n",
            "Training fold 1...\n",
            "Epoch 1/5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1762237821.844092    1083 service.cc:152] XLA service 0x7f2090004930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1762237821.844135    1083 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-11-04 06:30:21.926321: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1762237822.337920    1083 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-11-04 06:30:23.327747: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.39 = (f32[16,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,3,128,128]{3,2,1,0} %bitcast.6270, f32[64,3,3,3]{3,2,1,0} %bitcast.6277, f32[64]{0} %bitcast.6279), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block1_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 06:30:23.478829: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.40 = (f32[16,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,128,128]{3,2,1,0} %bitcast.6284, f32[64,64,3,3]{3,2,1,0} %bitcast.6291, f32[64]{0} %bitcast.6293), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block1_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 06:30:24.055141: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.41 = (f32[16,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,64,64]{3,2,1,0} %bitcast.6301, f32[128,64,3,3]{3,2,1,0} %bitcast.6308, f32[128]{0} %bitcast.6310), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block2_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 06:30:24.259093: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.42 = (f32[16,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,64,64]{3,2,1,0} %bitcast.6315, f32[128,128,3,3]{3,2,1,0} %bitcast.6322, f32[128]{0} %bitcast.6324), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block2_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 06:30:24.673647: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.43 = (f32[16,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,32,32]{3,2,1,0} %bitcast.6330, f32[256,128,3,3]{3,2,1,0} %bitcast.6337, f32[256]{0} %bitcast.6339), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block3_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 06:30:24.869552: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.44 = (f32[16,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,32,32]{3,2,1,0} %bitcast.6344, f32[256,256,3,3]{3,2,1,0} %bitcast.6351, f32[256]{0} %bitcast.6353), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block3_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 06:30:25.378966: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.46 = (f32[16,512,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,16,16]{3,2,1,0} %bitcast.6373, f32[512,256,3,3]{3,2,1,0} %bitcast.6380, f32[512]{0} %bitcast.6382), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block4_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 06:30:25.563212: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.47 = (f32[16,512,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,16,16]{3,2,1,0} %bitcast.6387, f32[512,512,3,3]{3,2,1,0} %bitcast.6394, f32[512]{0} %bitcast.6396), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block4_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 06:30:26.074186: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.49 = (f32[16,512,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,8,8]{3,2,1,0} %bitcast.6416, f32[512,512,3,3]{3,2,1,0} %bitcast.6423, f32[512]{0} %bitcast.6425), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block5_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1762237828.065912    1083 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8582 - loss: 0.9014\n",
            "Epoch 1: val_loss improved from inf to 5.60715, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 48ms/step - accuracy: 0.8582 - loss: 0.9013 - val_accuracy: 0.2239 - val_loss: 5.6071 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8760 - loss: 0.6034\n",
            "Epoch 2: val_loss improved from 5.60715 to 4.65193, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 48ms/step - accuracy: 0.8760 - loss: 0.6032 - val_accuracy: 0.2973 - val_loss: 4.6519 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9222 - loss: 0.3421\n",
            "Epoch 3: val_loss did not improve from 4.65193\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.9222 - loss: 0.3420 - val_accuracy: 0.3246 - val_loss: 5.0108 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9420 - loss: 0.2841\n",
            "Epoch 4: val_loss improved from 4.65193 to 4.45434, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 48ms/step - accuracy: 0.9420 - loss: 0.2840 - val_accuracy: 0.3789 - val_loss: 4.4543 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9423 - loss: 0.2818\n",
            "Epoch 5: val_loss improved from 4.45434 to 4.36983, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 48ms/step - accuracy: 0.9424 - loss: 0.2817 - val_accuracy: 0.3995 - val_loss: 4.3698 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "Time taken for fold 1: 611.708 seconds\n",
            "Training fold 2...\n",
            "Epoch 1/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9512 - loss: 0.2303\n",
            "Epoch 1: val_loss improved from inf to 4.11775, saving model to /content/RadImageNet/fashion_Eff_output/models/model_2.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 48ms/step - accuracy: 0.9512 - loss: 0.2303 - val_accuracy: 0.4151 - val_loss: 4.1177 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9507 - loss: 0.2135\n",
            "Epoch 2: val_loss did not improve from 4.11775\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 48ms/step - accuracy: 0.9507 - loss: 0.2135 - val_accuracy: 0.4232 - val_loss: 4.2176 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9556 - loss: 0.1940\n",
            "Epoch 3: val_loss did not improve from 4.11775\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 49ms/step - accuracy: 0.9556 - loss: 0.1940 - val_accuracy: 0.4114 - val_loss: 5.4603 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9542 - loss: 0.2147\n",
            "Epoch 4: val_loss did not improve from 4.11775\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 48ms/step - accuracy: 0.9542 - loss: 0.2147 - val_accuracy: 0.4169 - val_loss: 4.6319 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9557 - loss: 0.1772\n",
            "Epoch 5: val_loss did not improve from 4.11775\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.9557 - loss: 0.1772 - val_accuracy: 0.4672 - val_loss: 4.3223 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Time taken for fold 2: 605.891 seconds\n",
            "Training fold 3...\n",
            "Epoch 1/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9532 - loss: 0.1966\n",
            "Epoch 1: val_loss improved from inf to 4.42473, saving model to /content/RadImageNet/fashion_Eff_output/models/model_3.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 48ms/step - accuracy: 0.9532 - loss: 0.1966 - val_accuracy: 0.4226 - val_loss: 4.4247 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9516 - loss: 0.2069\n",
            "Epoch 2: val_loss improved from 4.42473 to 4.37399, saving model to /content/RadImageNet/fashion_Eff_output/models/model_3.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 48ms/step - accuracy: 0.9516 - loss: 0.2068 - val_accuracy: 0.4344 - val_loss: 4.3740 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9534 - loss: 0.2102\n",
            "Epoch 3: val_loss did not improve from 4.37399\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 48ms/step - accuracy: 0.9534 - loss: 0.2101 - val_accuracy: 0.4220 - val_loss: 4.6002 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9540 - loss: 0.2167\n",
            "Epoch 4: val_loss improved from 4.37399 to 3.99840, saving model to /content/RadImageNet/fashion_Eff_output/models/model_3.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 48ms/step - accuracy: 0.9541 - loss: 0.2166 - val_accuracy: 0.4589 - val_loss: 3.9984 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9600 - loss: 0.1708\n",
            "Epoch 5: val_loss did not improve from 3.99840\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 48ms/step - accuracy: 0.9600 - loss: 0.1708 - val_accuracy: 0.4115 - val_loss: 4.9788 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "Time taken for fold 3: 602.177 seconds\n",
            "Total training time for 3 folds: 1819.776 seconds\n",
            "Training the model on the entire dataset...\n",
            "Epoch 1/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 32ms/step - accuracy: 0.9716 - loss: 0.1234\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 32ms/step - accuracy: 0.9733 - loss: 0.1069\n",
            "Epoch 3/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 32ms/step - accuracy: 0.9737 - loss: 0.1166\n",
            "Epoch 4/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 32ms/step - accuracy: 0.9738 - loss: 0.1169\n",
            "Epoch 5/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 32ms/step - accuracy: 0.9749 - loss: 0.1087\n",
            "Time taken to train on the entire dataset: 611.515 seconds\n",
            "Final training accuracy on the entire dataset: 98.173%\n",
            "Final training loss on the entire dataset: 0.070\n",
            "Final model weights saved at: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Cross-validation results - Mean Accuracy: 96.4%, Mean Loss: 0.143\n",
            "Loading test data paths and labels....\n",
            "DataLoader (test): Found categories: ['Coat', 'Sandal', 'T-shirt', 'Bag', 'Sneaker', 'Dress', 'Ankle boot', 'Pullover', 'Shirt', 'Trouser'] in /content/RadImageNet/fashion_mnist_full_dataset/test\n",
            "DataLoader (test): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/test/Coat\n",
            "DataLoader (test): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/test/Sandal\n",
            "DataLoader (test): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/T-shirt\n",
            "DataLoader (test): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/test/Bag\n",
            "DataLoader (test): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/test/Sneaker\n",
            "DataLoader (test): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/test/Dress\n",
            "DataLoader (test): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/test/Ankle boot\n",
            "DataLoader (test): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/test/Pullover\n",
            "DataLoader (test): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/Shirt\n",
            "DataLoader (test): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/test/Trouser\n",
            "DataLoader (test): Total images found: 10000\n",
            "DataLoader (test): Total labels found: 10000\n",
            "DataLoader (test): Number of unique labels after encoding: 10\n",
            "Test data: 10000 images, 10 classes\n",
            "Evaluating model on unseen test data...\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "Loaded model weights from: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Predicting on test data...\n",
            "2025-11-04 07:10:51.606219: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.39 = (f32[32,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,128,128]{3,2,1,0} %bitcast.520, f32[64,3,3,3]{3,2,1,0} %bitcast.527, f32[64]{0} %bitcast.529), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block1_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:10:51.684320: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.40 = (f32[32,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,128,128]{3,2,1,0} %bitcast.534, f32[64,64,3,3]{3,2,1,0} %bitcast.541, f32[64]{0} %bitcast.543), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block1_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:10:52.817009: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.41 = (f32[32,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,64,64]{3,2,1,0} %bitcast.550, f32[128,64,3,3]{3,2,1,0} %bitcast.557, f32[128]{0} %bitcast.559), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block2_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:10:53.200810: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.42 = (f32[32,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,64,64]{3,2,1,0} %bitcast.564, f32[128,128,3,3]{3,2,1,0} %bitcast.571, f32[128]{0} %bitcast.573), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block2_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:10:53.925185: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.43 = (f32[32,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,32,32]{3,2,1,0} %bitcast.579, f32[256,128,3,3]{3,2,1,0} %bitcast.586, f32[256]{0} %bitcast.588), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block3_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:10:54.431265: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.44 = (f32[32,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,32,32]{3,2,1,0} %bitcast.593, f32[256,256,3,3]{3,2,1,0} %bitcast.600, f32[256]{0} %bitcast.602), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block3_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:10:55.263679: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.46 = (f32[32,512,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,16,16]{3,2,1,0} %bitcast.622, f32[512,256,3,3]{3,2,1,0} %bitcast.629, f32[512]{0} %bitcast.631), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block4_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:10:55.590672: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.47 = (f32[32,512,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,16,16]{3,2,1,0} %bitcast.636, f32[512,512,3,3]{3,2,1,0} %bitcast.643, f32[512]{0} %bitcast.645), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block4_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:10:56.530867: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.49 = (f32[32,512,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,8,8]{3,2,1,0} %bitcast.665, f32[512,512,3,3]{3,2,1,0} %bitcast.672, f32[512]{0} %bitcast.674), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block5_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 60ms/step\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Ankle boot       0.37      1.00      0.54      1000\n",
            "         Bag       0.99      0.57      0.73      1000\n",
            "        Coat       1.00      0.01      0.03      1000\n",
            "       Dress       1.00      0.00      0.00      1000\n",
            "    Pullover       0.98      0.11      0.19      1000\n",
            "      Sandal       1.00      0.26      0.41      1000\n",
            "       Shirt       0.21      0.95      0.34      1000\n",
            "     Sneaker       0.69      0.03      0.05      1000\n",
            "     T-shirt       0.00      0.00      0.00      1000\n",
            "     Trouser       0.58      1.00      0.73      1000\n",
            "\n",
            "    accuracy                           0.39     10000\n",
            "   macro avg       0.68      0.39      0.30     10000\n",
            "weighted avg       0.68      0.39      0.30     10000\n",
            "\n",
            "Classification report saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/classification_report.txt\n",
            "\n",
            "Confusion Matrix:\n",
            "[[996   0   0   0   0   0   2   0   0   2]\n",
            " [ 18 573   0   0   1   0 387   0   0  21]\n",
            " [  0   0  15   0   1   0 939   0   0  45]\n",
            " [  0   0   0   1   0   0 478   0   0 521]\n",
            " [  0   0   0   0 106   0 863   0   0  31]\n",
            " [707   6   0   0   0 261  14  11   0   1]\n",
            " [  0   0   0   0   0   0 947   0   0  53]\n",
            " [975   0   0   0   0   0   0  25   0   0]\n",
            " [  1   0   0   0   0   0 938   0   0  61]\n",
            " [  0   0   0   0   0   0   1   0   0 999]]\n",
            "Confusion matrix saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/confusion_matrix.png\n",
            "Predictions saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/predictions.csv\n"
          ]
        }
      ],
      "source": [
        "!python main.py \\\n",
        "    --model_name VGG16 \\\n",
        "    --train_dir /content/RadImageNet/fashion_mnist_full_dataset/train \\\n",
        "    --test_dir /content/RadImageNet/fashion_mnist_full_dataset/test \\\n",
        "    --output_dir /content/RadImageNet/fashion_Eff_output \\\n",
        "    --lr 0.0001 \\\n",
        "    --batch_size 16 \\\n",
        "    --epochs 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "    --model_name VGG19 \\\n",
        "    --train_dir /content/RadImageNet/fashion_mnist_full_dataset/train \\\n",
        "    --test_dir /content/RadImageNet/fashion_mnist_full_dataset/test \\\n",
        "    --output_dir /content/RadImageNet/fashion_Eff_output \\\n",
        "    --lr 0.0001 \\\n",
        "    --batch_size 16 \\\n",
        "    --epochs 5"
      ],
      "metadata": {
        "id": "bpesR4S6aoVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a4550c-7fda-40e5-b68e-4ca77f066975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-04 07:25:11.770360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762241111.792475   15135 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762241111.798708   15135 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762241111.814731   15135 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762241111.814756   15135 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762241111.814760   15135 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762241111.814763   15135 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-04 07:25:11.819569: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2.19.0\n",
            "Number of GPUs available: 1\n",
            "Loading training data paths and labels...\n",
            "DataLoader (train): Found categories in directory: ['Coat', 'Sandal', 'T-shirt', 'Bag', 'Sneaker', 'Dress', 'Ankle boot', 'Pullover', 'Shirt', 'Trouser']\n",
            "DataLoader (train): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/train/Coat\n",
            "DataLoader (train): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/train/Sandal\n",
            "DataLoader (train): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/T-shirt\n",
            "DataLoader (train): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/train/Bag\n",
            "DataLoader (train): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/train/Sneaker\n",
            "DataLoader (train): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/train/Dress\n",
            "DataLoader (train): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/train/Ankle boot\n",
            "DataLoader (train): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/train/Pullover\n",
            "DataLoader (train): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/Shirt\n",
            "DataLoader (train): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/train/Trouser\n",
            "DataLoader (train): Total images found: 60000\n",
            "DataLoader (train): Total labels found: 60000\n",
            "DataLoader (train): Number of unique labels after encoding: 10\n",
            "Training data: 60000 images, 10 classes\n",
            "Building Model ....\n",
            "I0000 00:00:1762241119.717271   15135 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "Training and cross-validating model...\n",
            "Training fold 1...\n",
            "Epoch 1/5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1762241124.086270   15189 service.cc:152] XLA service 0x7a71cc012540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1762241124.086330   15189 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-11-04 07:25:24.136161: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1762241124.538905   15189 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-11-04 07:25:25.003864: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.48 = (f32[16,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,3,128,128]{3,2,1,0} %bitcast.6351, f32[64,3,3,3]{3,2,1,0} %bitcast.6358, f32[64]{0} %bitcast.6360), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block1_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:25:25.094819: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.49 = (f32[16,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,128,128]{3,2,1,0} %bitcast.6365, f32[64,64,3,3]{3,2,1,0} %bitcast.6372, f32[64]{0} %bitcast.6374), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block1_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:25:25.599850: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.50 = (f32[16,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,64,64]{3,2,1,0} %bitcast.6382, f32[128,64,3,3]{3,2,1,0} %bitcast.6389, f32[128]{0} %bitcast.6391), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block2_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:25:25.819783: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.51 = (f32[16,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,64,64]{3,2,1,0} %bitcast.6396, f32[128,128,3,3]{3,2,1,0} %bitcast.6403, f32[128]{0} %bitcast.6405), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block2_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:25:26.174503: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.52 = (f32[16,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,32,32]{3,2,1,0} %bitcast.6411, f32[256,128,3,3]{3,2,1,0} %bitcast.6418, f32[256]{0} %bitcast.6420), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block3_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:25:26.346428: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.53 = (f32[16,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,32,32]{3,2,1,0} %bitcast.6425, f32[256,256,3,3]{3,2,1,0} %bitcast.6432, f32[256]{0} %bitcast.6434), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block3_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:25:26.757947: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.56 = (f32[16,512,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,16,16]{3,2,1,0} %bitcast.6468, f32[512,256,3,3]{3,2,1,0} %bitcast.6475, f32[512]{0} %bitcast.6477), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block4_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:25:26.928881: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.57 = (f32[16,512,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,16,16]{3,2,1,0} %bitcast.6482, f32[512,512,3,3]{3,2,1,0} %bitcast.6489, f32[512]{0} %bitcast.6491), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block4_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 07:25:27.357732: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.60 = (f32[16,512,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,8,8]{3,2,1,0} %bitcast.6525, f32[512,512,3,3]{3,2,1,0} %bitcast.6532, f32[512]{0} %bitcast.6534), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/block5_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1762241129.068003   15189 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8370 - loss: 1.2556\n",
            "Epoch 1: val_loss improved from inf to 6.10317, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 60ms/step - accuracy: 0.8370 - loss: 1.2551 - val_accuracy: 0.2189 - val_loss: 6.1032 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8556 - loss: 0.7201\n",
            "Epoch 2: val_loss improved from 6.10317 to 4.31475, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.8557 - loss: 0.7199 - val_accuracy: 0.3161 - val_loss: 4.3147 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9056 - loss: 0.4496\n",
            "Epoch 3: val_loss did not improve from 4.31475\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 61ms/step - accuracy: 0.9057 - loss: 0.4495 - val_accuracy: 0.3435 - val_loss: 4.3745 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9220 - loss: 0.3894\n",
            "Epoch 4: val_loss improved from 4.31475 to 4.05635, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9220 - loss: 0.3893 - val_accuracy: 0.3801 - val_loss: 4.0563 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9356 - loss: 0.3267\n",
            "Epoch 5: val_loss did not improve from 4.05635\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9357 - loss: 0.3267 - val_accuracy: 0.3851 - val_loss: 4.2770 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "Time taken for fold 1: 819.911 seconds\n",
            "Training fold 2...\n",
            "Epoch 1/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9389 - loss: 0.3103\n",
            "Epoch 1: val_loss improved from inf to 4.12617, saving model to /content/RadImageNet/fashion_Eff_output/models/model_2.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9389 - loss: 0.3103 - val_accuracy: 0.3809 - val_loss: 4.1262 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9401 - loss: 0.2902\n",
            "Epoch 2: val_loss improved from 4.12617 to 3.66722, saving model to /content/RadImageNet/fashion_Eff_output/models/model_2.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9402 - loss: 0.2901 - val_accuracy: 0.4198 - val_loss: 3.6672 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9456 - loss: 0.2535\n",
            "Epoch 3: val_loss did not improve from 3.66722\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9456 - loss: 0.2535 - val_accuracy: 0.4260 - val_loss: 3.7567 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9491 - loss: 0.2374\n",
            "Epoch 4: val_loss did not improve from 3.66722\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9491 - loss: 0.2373 - val_accuracy: 0.4658 - val_loss: 3.7494 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9532 - loss: 0.2264\n",
            "Epoch 5: val_loss did not improve from 3.66722\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9532 - loss: 0.2263 - val_accuracy: 0.4383 - val_loss: 3.9813 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "Time taken for fold 2: 764.776 seconds\n",
            "Training fold 3...\n",
            "Epoch 1/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9452 - loss: 0.2657\n",
            "Epoch 1: val_loss improved from inf to 3.87361, saving model to /content/RadImageNet/fashion_Eff_output/models/model_3.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9452 - loss: 0.2656 - val_accuracy: 0.4112 - val_loss: 3.8736 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9468 - loss: 0.2462\n",
            "Epoch 2: val_loss did not improve from 3.87361\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9468 - loss: 0.2461 - val_accuracy: 0.4339 - val_loss: 4.1693 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9503 - loss: 0.2210\n",
            "Epoch 3: val_loss did not improve from 3.87361\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 61ms/step - accuracy: 0.9503 - loss: 0.2210 - val_accuracy: 0.4317 - val_loss: 4.1459 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9525 - loss: 0.2303\n",
            "Epoch 4: val_loss did not improve from 3.87361\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 61ms/step - accuracy: 0.9525 - loss: 0.2303 - val_accuracy: 0.4130 - val_loss: 4.2332 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9516 - loss: 0.2293\n",
            "Epoch 5: val_loss did not improve from 3.87361\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 61ms/step - accuracy: 0.9516 - loss: 0.2292 - val_accuracy: 0.4354 - val_loss: 4.1199 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Time taken for fold 3: 764.694 seconds\n",
            "Total training time for 3 folds: 2349.381 seconds\n",
            "Training the model on the entire dataset...\n",
            "Epoch 1/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 41ms/step - accuracy: 0.9660 - loss: 0.1567\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 41ms/step - accuracy: 0.9686 - loss: 0.1706\n",
            "Epoch 3/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 41ms/step - accuracy: 0.9683 - loss: 0.1545\n",
            "Epoch 4/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 41ms/step - accuracy: 0.9698 - loss: 0.1422\n",
            "Epoch 5/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 41ms/step - accuracy: 0.9707 - loss: 0.1418\n",
            "Time taken to train on the entire dataset: 768.433 seconds\n",
            "Final training accuracy on the entire dataset: 97.960%\n",
            "Final training loss on the entire dataset: 0.084\n",
            "Final model weights saved at: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Cross-validation results - Mean Accuracy: 96.3%, Mean Loss: 0.152\n",
            "Loading test data paths and labels....\n",
            "DataLoader (test): Found categories: ['Coat', 'Sandal', 'T-shirt', 'Bag', 'Sneaker', 'Dress', 'Ankle boot', 'Pullover', 'Shirt', 'Trouser'] in /content/RadImageNet/fashion_mnist_full_dataset/test\n",
            "DataLoader (test): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/test/Coat\n",
            "DataLoader (test): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/test/Sandal\n",
            "DataLoader (test): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/T-shirt\n",
            "DataLoader (test): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/test/Bag\n",
            "DataLoader (test): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/test/Sneaker\n",
            "DataLoader (test): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/test/Dress\n",
            "DataLoader (test): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/test/Ankle boot\n",
            "DataLoader (test): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/test/Pullover\n",
            "DataLoader (test): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/Shirt\n",
            "DataLoader (test): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/test/Trouser\n",
            "DataLoader (test): Total images found: 10000\n",
            "DataLoader (test): Total labels found: 10000\n",
            "DataLoader (test): Number of unique labels after encoding: 10\n",
            "Test data: 10000 images, 10 classes\n",
            "Evaluating model on unseen test data...\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "Loaded model weights from: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Predicting on test data...\n",
            "2025-11-04 08:17:20.717361: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.48 = (f32[32,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,128,128]{3,2,1,0} %bitcast.601, f32[64,3,3,3]{3,2,1,0} %bitcast.608, f32[64]{0} %bitcast.610), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block1_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:17:20.795546: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.49 = (f32[32,64,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,128,128]{3,2,1,0} %bitcast.615, f32[64,64,3,3]{3,2,1,0} %bitcast.622, f32[64]{0} %bitcast.624), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block1_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:17:21.989146: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.50 = (f32[32,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,64,64]{3,2,1,0} %bitcast.631, f32[128,64,3,3]{3,2,1,0} %bitcast.638, f32[128]{0} %bitcast.640), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block2_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:17:22.371931: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.51 = (f32[32,128,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,64,64]{3,2,1,0} %bitcast.645, f32[128,128,3,3]{3,2,1,0} %bitcast.652, f32[128]{0} %bitcast.654), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block2_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:17:23.186801: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.52 = (f32[32,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,32,32]{3,2,1,0} %bitcast.660, f32[256,128,3,3]{3,2,1,0} %bitcast.667, f32[256]{0} %bitcast.669), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block3_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:17:23.704386: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.53 = (f32[32,256,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,32,32]{3,2,1,0} %bitcast.674, f32[256,256,3,3]{3,2,1,0} %bitcast.681, f32[256]{0} %bitcast.683), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block3_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:17:24.569076: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.56 = (f32[32,512,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,16,16]{3,2,1,0} %bitcast.717, f32[512,256,3,3]{3,2,1,0} %bitcast.724, f32[512]{0} %bitcast.726), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block4_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:17:24.882252: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.57 = (f32[32,512,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,16,16]{3,2,1,0} %bitcast.731, f32[512,512,3,3]{3,2,1,0} %bitcast.738, f32[512]{0} %bitcast.740), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block4_conv2_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:17:25.820672: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.60 = (f32[32,512,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,8,8]{3,2,1,0} %bitcast.774, f32[512,512,3,3]{3,2,1,0} %bitcast.781, f32[512]{0} %bitcast.783), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/block5_conv1_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 76ms/step\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Ankle boot       0.43      0.99      0.60      1000\n",
            "         Bag       1.00      0.54      0.70      1000\n",
            "        Coat       1.00      0.07      0.14      1000\n",
            "       Dress       0.00      0.00      0.00      1000\n",
            "    Pullover       0.96      0.13      0.23      1000\n",
            "      Sandal       1.00      0.39      0.56      1000\n",
            "       Shirt       0.21      0.94      0.34      1000\n",
            "     Sneaker       0.53      0.12      0.19      1000\n",
            "     T-shirt       0.00      0.00      0.00      1000\n",
            "     Trouser       0.54      1.00      0.70      1000\n",
            "\n",
            "    accuracy                           0.42     10000\n",
            "   macro avg       0.57      0.42      0.35     10000\n",
            "weighted avg       0.57      0.42      0.35     10000\n",
            "\n",
            "Classification report saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/classification_report.txt\n",
            "\n",
            "Confusion Matrix:\n",
            "[[990   0   0   0   0   0   8   0   0   2]\n",
            " [  9 535   0   0   0   0 423   0   0  33]\n",
            " [  0   0  74   0   2   0 858   0   0  66]\n",
            " [  0   0   0   0   2   0 460   0   0 538]\n",
            " [  0   0   0   0 133   0 830   0   0  37]\n",
            " [437   1   0   0   0 386  42 103   0  31]\n",
            " [  0   0   0   0   0   0 939   0   0  61]\n",
            " [881   0   0   0   0   0   1 118   0   0]\n",
            " [  0   0   0   0   1   0 911   0   0  88]\n",
            " [  0   0   0   0   0   0   3   0   0 997]]\n",
            "Confusion matrix saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/confusion_matrix.png\n",
            "Predictions saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "    --model_name ResNet50 \\\n",
        "    --train_dir /content/RadImageNet/fashion_mnist_full_dataset/train \\\n",
        "    --test_dir /content/RadImageNet/fashion_mnist_full_dataset/test \\\n",
        "    --output_dir /content/RadImageNet/fashion_Eff_output \\\n",
        "    --lr 0.0001 \\\n",
        "    --batch_size 16 \\\n",
        "    --epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlKXGmpGVE5P",
        "outputId": "cd0fcf9f-add9-400f-9a4e-f55e11b7302b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-04 08:18:22.020447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762244302.040711   28962 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762244302.046922   28962 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762244302.062393   28962 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762244302.062417   28962 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762244302.062421   28962 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762244302.062424   28962 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-04 08:18:22.067212: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2.19.0\n",
            "Number of GPUs available: 1\n",
            "Loading training data paths and labels...\n",
            "DataLoader (train): Found categories in directory: ['Coat', 'Sandal', 'T-shirt', 'Bag', 'Sneaker', 'Dress', 'Ankle boot', 'Pullover', 'Shirt', 'Trouser']\n",
            "DataLoader (train): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/train/Coat\n",
            "DataLoader (train): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/train/Sandal\n",
            "DataLoader (train): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/T-shirt\n",
            "DataLoader (train): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/train/Bag\n",
            "DataLoader (train): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/train/Sneaker\n",
            "DataLoader (train): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/train/Dress\n",
            "DataLoader (train): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/train/Ankle boot\n",
            "DataLoader (train): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/train/Pullover\n",
            "DataLoader (train): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/Shirt\n",
            "DataLoader (train): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/train/Trouser\n",
            "DataLoader (train): Total images found: 60000\n",
            "DataLoader (train): Total labels found: 60000\n",
            "DataLoader (train): Number of unique labels after encoding: 10\n",
            "Training data: 60000 images, 10 classes\n",
            "Building Model ....\n",
            "I0000 00:00:1762244309.991749   28962 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "Training and cross-validating model...\n",
            "Training fold 1...\n",
            "Epoch 1/5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1762244319.911406   29020 service.cc:152] XLA service 0x7c1f84004570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1762244319.911450   29020 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-11-04 08:18:40.191652: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1762244322.052016   29020 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-11-04 08:18:42.860890: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[16,64,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,32,32]{3,2,1,0} %bitcast.10295, f32[64,64,3,3]{3,2,1,0} %bitcast.10302, f32[64]{0} %bitcast.10304), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:18:43.050504: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[16,128,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,16,16]{3,2,1,0} %bitcast.10700, f32[128,128,3,3]{3,2,1,0} %bitcast.10707, f32[128]{0} %bitcast.10709), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:18:43.216172: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[16,256,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,8,8]{3,2,1,0} %bitcast.11228, f32[256,256,3,3]{3,2,1,0} %bitcast.11235, f32[256]{0} %bitcast.11237), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:18:43.395734: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[16,512,4,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,512,4,4]{3,2,1,0} %bitcast.12002, f32[512,512,3,3]{3,2,1,0} %bitcast.12009, f32[512]{0} %bitcast.12011), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1762244325.776584   29020 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9307 - loss: 0.3083\n",
            "Epoch 1: val_loss improved from inf to 5.28010, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 40ms/step - accuracy: 0.9307 - loss: 0.3083 - val_accuracy: 0.2779 - val_loss: 5.2801 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9320 - loss: 0.3355\n",
            "Epoch 2: val_loss improved from 5.28010 to 4.03156, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 33ms/step - accuracy: 0.9321 - loss: 0.3353 - val_accuracy: 0.3695 - val_loss: 4.0316 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9542 - loss: 0.2054\n",
            "Epoch 3: val_loss did not improve from 4.03156\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 39ms/step - accuracy: 0.9543 - loss: 0.2054 - val_accuracy: 0.4276 - val_loss: 4.1860 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9593 - loss: 0.1824\n",
            "Epoch 4: val_loss improved from 4.03156 to 3.85453, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 33ms/step - accuracy: 0.9593 - loss: 0.1823 - val_accuracy: 0.4426 - val_loss: 3.8545 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9631 - loss: 0.1689\n",
            "Epoch 5: val_loss did not improve from 3.85453\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 39ms/step - accuracy: 0.9631 - loss: 0.1688 - val_accuracy: 0.4606 - val_loss: 3.9234 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "Time taken for fold 1: 474.642 seconds\n",
            "Training fold 2...\n",
            "Epoch 1/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9640 - loss: 0.1631\n",
            "Epoch 1: val_loss improved from inf to 3.74081, saving model to /content/RadImageNet/fashion_Eff_output/models/model_2.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 33ms/step - accuracy: 0.9640 - loss: 0.1630 - val_accuracy: 0.4433 - val_loss: 3.7408 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9608 - loss: 0.1629\n",
            "Epoch 2: val_loss did not improve from 3.74081\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 33ms/step - accuracy: 0.9608 - loss: 0.1629 - val_accuracy: 0.4615 - val_loss: 4.1894 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9638 - loss: 0.1501\n",
            "Epoch 3: val_loss did not improve from 3.74081\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 34ms/step - accuracy: 0.9638 - loss: 0.1501 - val_accuracy: 0.4661 - val_loss: 4.2384 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9653 - loss: 0.1374\n",
            "Epoch 4: val_loss did not improve from 3.74081\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 33ms/step - accuracy: 0.9653 - loss: 0.1373 - val_accuracy: 0.4913 - val_loss: 3.7670 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9693 - loss: 0.1284\n",
            "Epoch 5: val_loss did not improve from 3.74081\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 39ms/step - accuracy: 0.9693 - loss: 0.1284 - val_accuracy: 0.4696 - val_loss: 4.1834 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Time taken for fold 2: 437.163 seconds\n",
            "Training fold 3...\n",
            "Epoch 1/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9633 - loss: 0.1531\n",
            "Epoch 1: val_loss improved from inf to 3.62658, saving model to /content/RadImageNet/fashion_Eff_output/models/model_3.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 33ms/step - accuracy: 0.9633 - loss: 0.1530 - val_accuracy: 0.4763 - val_loss: 3.6266 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9626 - loss: 0.1553\n",
            "Epoch 2: val_loss did not improve from 3.62658\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 33ms/step - accuracy: 0.9626 - loss: 0.1553 - val_accuracy: 0.4651 - val_loss: 4.0077 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9635 - loss: 0.1486\n",
            "Epoch 3: val_loss did not improve from 3.62658\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 33ms/step - accuracy: 0.9635 - loss: 0.1485 - val_accuracy: 0.4637 - val_loss: 4.3555 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9704 - loss: 0.1415\n",
            "Epoch 4: val_loss did not improve from 3.62658\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 33ms/step - accuracy: 0.9704 - loss: 0.1414 - val_accuracy: 0.4689 - val_loss: 4.3936 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9671 - loss: 0.1469\n",
            "Epoch 5: val_loss did not improve from 3.62658\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 32ms/step - accuracy: 0.9671 - loss: 0.1469 - val_accuracy: 0.4988 - val_loss: 4.2942 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Time taken for fold 3: 414.524 seconds\n",
            "Total training time for 3 folds: 1326.329 seconds\n",
            "Training the model on the entire dataset...\n",
            "Epoch 1/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 23ms/step - accuracy: 0.9766 - loss: 0.1033\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 23ms/step - accuracy: 0.9788 - loss: 0.1082\n",
            "Epoch 3/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 22ms/step - accuracy: 0.9778 - loss: 0.0973\n",
            "Epoch 4/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 23ms/step - accuracy: 0.9792 - loss: 0.1000\n",
            "Epoch 5/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 23ms/step - accuracy: 0.9792 - loss: 0.1000\n",
            "Time taken to train on the entire dataset: 429.777 seconds\n",
            "Final training accuracy on the entire dataset: 98.697%\n",
            "Final training loss on the entire dataset: 0.059\n",
            "Final model weights saved at: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Cross-validation results - Mean Accuracy: 97.7%, Mean Loss: 0.095\n",
            "Loading test data paths and labels....\n",
            "DataLoader (test): Found categories: ['Coat', 'Sandal', 'T-shirt', 'Bag', 'Sneaker', 'Dress', 'Ankle boot', 'Pullover', 'Shirt', 'Trouser'] in /content/RadImageNet/fashion_mnist_full_dataset/test\n",
            "DataLoader (test): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/test/Coat\n",
            "DataLoader (test): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/test/Sandal\n",
            "DataLoader (test): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/T-shirt\n",
            "DataLoader (test): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/test/Bag\n",
            "DataLoader (test): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/test/Sneaker\n",
            "DataLoader (test): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/test/Dress\n",
            "DataLoader (test): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/test/Ankle boot\n",
            "DataLoader (test): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/test/Pullover\n",
            "DataLoader (test): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/Shirt\n",
            "DataLoader (test): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/test/Trouser\n",
            "DataLoader (test): Total images found: 10000\n",
            "DataLoader (test): Total labels found: 10000\n",
            "DataLoader (test): Number of unique labels after encoding: 10\n",
            "Test data: 10000 images, 10 classes\n",
            "Evaluating model on unseen test data...\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "Loaded model weights from: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Predicting on test data...\n",
            "2025-11-04 08:47:53.938442: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.162 = (f32[32,64,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,32,32]{3,2,1,0} %bitcast.4543, f32[64,64,3,3]{3,2,1,0} %bitcast.4550, f32[64]{0} %bitcast.4552), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:47:54.145704: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.172 = (f32[32,128,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,16,16]{3,2,1,0} %bitcast.4948, f32[128,128,3,3]{3,2,1,0} %bitcast.4955, f32[128]{0} %bitcast.4957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv3_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:47:54.359782: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.185 = (f32[32,256,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,8,8]{3,2,1,0} %bitcast.5476, f32[256,256,3,3]{3,2,1,0} %bitcast.5483, f32[256]{0} %bitcast.5485), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv4_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-11-04 08:47:54.575674: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.204 = (f32[32,512,4,4]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,4,4]{3,2,1,0} %bitcast.6250, f32[512,512,3,3]{3,2,1,0} %bitcast.6257, f32[512]{0} %bitcast.6259), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv5_block1_2_conv_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Ankle boot       0.51      0.96      0.67      1000\n",
            "         Bag       1.00      0.65      0.79      1000\n",
            "        Coat       0.94      0.01      0.03      1000\n",
            "       Dress       0.00      0.00      0.00      1000\n",
            "    Pullover       0.91      0.24      0.38      1000\n",
            "      Sandal       1.00      0.46      0.63      1000\n",
            "       Shirt       0.24      0.85      0.37      1000\n",
            "     Sneaker       0.62      0.32      0.43      1000\n",
            "     T-shirt       0.00      0.00      0.00      1000\n",
            "     Trouser       0.37      1.00      0.54      1000\n",
            "\n",
            "    accuracy                           0.45     10000\n",
            "   macro avg       0.56      0.45      0.38     10000\n",
            "weighted avg       0.56      0.45      0.38     10000\n",
            "\n",
            "Classification report saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/classification_report.txt\n",
            "\n",
            "Confusion Matrix:\n",
            "[[956   0   0   0   0   1  16   1   0  26]\n",
            " [ 32 651   0   0   7   0 240   5   0  65]\n",
            " [  0   0  15   0  13   0 701   0   0 271]\n",
            " [  0   0   0   0   1   0 283   0   0 716]\n",
            " [  0   0   1   0 239   0 561   0   0 199]\n",
            " [204   0   0   0   0 458  22 190   0 126]\n",
            " [  0   0   0   0   1   0 855   0   0 144]\n",
            " [670   0   0   0   0   1   3 323   0   3]\n",
            " [  0   0   0   0   1   0 879   0   0 120]\n",
            " [  0   0   0   0   0   0   2   0   0 998]]\n",
            "Confusion matrix saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/confusion_matrix.png\n",
            "Predictions saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "    --model_name DenseNet121 \\\n",
        "    --train_dir /content/RadImageNet/fashion_mnist_full_dataset/train \\\n",
        "    --test_dir /content/RadImageNet/fashion_mnist_full_dataset/test \\\n",
        "    --output_dir /content/RadImageNet/fashion_Eff_output \\\n",
        "    --lr 0.0001 \\\n",
        "    --batch_size 16 \\\n",
        "    --epochs 5"
      ],
      "metadata": {
        "id": "EnBUnWf9VE56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80d1f1f-5de1-42ae-ed6f-335fbfd64f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-06 15:59:48.875957: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762444788.907675    1358 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762444788.917104    1358 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762444788.940101    1358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762444788.940130    1358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762444788.940138    1358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762444788.940145    1358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-06 15:59:48.946606: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2.19.0\n",
            "Number of GPUs available: 1\n",
            "Loading training data paths and labels...\n",
            "DataLoader (train): Found categories in directory: ['T-shirt', 'Ankle boot', 'Trouser', 'Sneaker', 'Coat', 'Bag', 'Shirt', 'Dress', 'Pullover', 'Sandal']\n",
            "DataLoader (train): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/T-shirt\n",
            "DataLoader (train): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/train/Ankle boot\n",
            "DataLoader (train): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/train/Trouser\n",
            "DataLoader (train): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/train/Sneaker\n",
            "DataLoader (train): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/train/Coat\n",
            "DataLoader (train): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/train/Bag\n",
            "DataLoader (train): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/Shirt\n",
            "DataLoader (train): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/train/Dress\n",
            "DataLoader (train): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/train/Pullover\n",
            "DataLoader (train): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/train/Sandal\n",
            "DataLoader (train): Total images found: 60000\n",
            "DataLoader (train): Total labels found: 60000\n",
            "DataLoader (train): Number of unique labels after encoding: 10\n",
            "Training data: 60000 images, 10 classes\n",
            "Building Model ....\n",
            "I0000 00:00:1762444797.545744    1358 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "Training and cross-validating model...\n",
            "Training fold 1...\n",
            "Epoch 1/5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1762444814.364427    1418 service.cc:152] XLA service 0x788038006700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1762444814.364491    1418 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-11-06 16:00:14.750503: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1762444817.429785    1418 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "I0000 00:00:1762444828.585249    1418 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9049 - loss: 0.4659\n",
            "Epoch 1: val_loss improved from inf to 7.61052, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 42ms/step - accuracy: 0.9049 - loss: 0.4658 - val_accuracy: 0.2433 - val_loss: 7.6105 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9344 - loss: 0.3675\n",
            "Epoch 2: val_loss improved from 7.61052 to 6.66815, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 43ms/step - accuracy: 0.9344 - loss: 0.3674 - val_accuracy: 0.2662 - val_loss: 6.6682 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9538 - loss: 0.2010\n",
            "Epoch 3: val_loss improved from 6.66815 to 6.55089, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 37ms/step - accuracy: 0.9539 - loss: 0.2010 - val_accuracy: 0.2835 - val_loss: 6.5509 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9616 - loss: 0.1738\n",
            "Epoch 4: val_loss improved from 6.55089 to 6.20361, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 38ms/step - accuracy: 0.9616 - loss: 0.1738 - val_accuracy: 0.3225 - val_loss: 6.2036 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9700 - loss: 0.1479\n",
            "Epoch 5: val_loss did not improve from 6.20361\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 37ms/step - accuracy: 0.9700 - loss: 0.1479 - val_accuracy: 0.3149 - val_loss: 6.5056 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "Time taken for fold 1: 526.654 seconds\n",
            "Training fold 2...\n",
            "Epoch 1/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9716 - loss: 0.1396\n",
            "Epoch 1: val_loss improved from inf to 6.35340, saving model to /content/RadImageNet/fashion_Eff_output/models/model_2.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 37ms/step - accuracy: 0.9716 - loss: 0.1396 - val_accuracy: 0.3277 - val_loss: 6.3534 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9698 - loss: 0.1434\n",
            "Epoch 2: val_loss did not improve from 6.35340\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 43ms/step - accuracy: 0.9698 - loss: 0.1433 - val_accuracy: 0.3280 - val_loss: 6.5022 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9734 - loss: 0.1333\n",
            "Epoch 3: val_loss did not improve from 6.35340\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 38ms/step - accuracy: 0.9734 - loss: 0.1332 - val_accuracy: 0.3161 - val_loss: 6.5339 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9721 - loss: 0.1272\n",
            "Epoch 4: val_loss did not improve from 6.35340\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 38ms/step - accuracy: 0.9721 - loss: 0.1272 - val_accuracy: 0.3471 - val_loss: 6.6355 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9744 - loss: 0.1154\n",
            "Epoch 5: val_loss improved from 6.35340 to 6.12699, saving model to /content/RadImageNet/fashion_Eff_output/models/model_2.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 44ms/step - accuracy: 0.9744 - loss: 0.1153 - val_accuracy: 0.3430 - val_loss: 6.1270 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "Time taken for fold 2: 505.812 seconds\n",
            "Training fold 3...\n",
            "Epoch 1/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9721 - loss: 0.1264\n",
            "Epoch 1: val_loss improved from inf to 5.95704, saving model to /content/RadImageNet/fashion_Eff_output/models/model_3.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 45ms/step - accuracy: 0.9721 - loss: 0.1263 - val_accuracy: 0.3770 - val_loss: 5.9570 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9760 - loss: 0.1087\n",
            "Epoch 2: val_loss did not improve from 5.95704\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 41ms/step - accuracy: 0.9760 - loss: 0.1087 - val_accuracy: 0.3633 - val_loss: 7.0353 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9730 - loss: 0.1274\n",
            "Epoch 3: val_loss did not improve from 5.95704\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 43ms/step - accuracy: 0.9730 - loss: 0.1274 - val_accuracy: 0.3636 - val_loss: 6.5650 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9737 - loss: 0.1186\n",
            "Epoch 4: val_loss did not improve from 5.95704\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 38ms/step - accuracy: 0.9737 - loss: 0.1186 - val_accuracy: 0.3576 - val_loss: 7.2130 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9705 - loss: 0.1315\n",
            "Epoch 5: val_loss did not improve from 5.95704\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 38ms/step - accuracy: 0.9705 - loss: 0.1315 - val_accuracy: 0.3891 - val_loss: 6.3435 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Time taken for fold 3: 560.601 seconds\n",
            "Total training time for 3 folds: 1593.067 seconds\n",
            "Training the model on the entire dataset...\n",
            "Epoch 1/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0762\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 27ms/step - accuracy: 0.9832 - loss: 0.0810\n",
            "Epoch 3/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 26ms/step - accuracy: 0.9844 - loss: 0.0839\n",
            "Epoch 4/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 26ms/step - accuracy: 0.9841 - loss: 0.0777\n",
            "Epoch 5/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 26ms/step - accuracy: 0.9857 - loss: 0.0692\n",
            "Time taken to train on the entire dataset: 500.699 seconds\n",
            "Final training accuracy on the entire dataset: 98.832%\n",
            "Final training loss on the entire dataset: 0.048\n",
            "Final model weights saved at: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Cross-validation results - Mean Accuracy: 97.8%, Mean Loss: 0.088\n",
            "Loading test data paths and labels....\n",
            "DataLoader (test): Found categories: ['T-shirt', 'Ankle boot', 'Trouser', 'Sneaker', 'Coat', 'Bag', 'Shirt', 'Dress', 'Pullover', 'Sandal'] in /content/RadImageNet/fashion_mnist_full_dataset/test\n",
            "DataLoader (test): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/T-shirt\n",
            "DataLoader (test): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/test/Ankle boot\n",
            "DataLoader (test): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/test/Trouser\n",
            "DataLoader (test): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/test/Sneaker\n",
            "DataLoader (test): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/test/Coat\n",
            "DataLoader (test): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/test/Bag\n",
            "DataLoader (test): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/Shirt\n",
            "DataLoader (test): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/test/Dress\n",
            "DataLoader (test): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/test/Pullover\n",
            "DataLoader (test): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/test/Sandal\n",
            "DataLoader (test): Total images found: 10000\n",
            "DataLoader (test): Total labels found: 10000\n",
            "DataLoader (test): Number of unique labels after encoding: 10\n",
            "Test data: 10000 images, 10 classes\n",
            "Evaluating model on unseen test data...\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "Loaded model weights from: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Predicting on test data...\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 67ms/step\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Ankle boot       0.00      0.00      0.00      1000\n",
            "         Bag       1.00      0.20      0.33      1000\n",
            "        Coat       0.00      0.00      0.00      1000\n",
            "       Dress       0.57      0.67      0.62      1000\n",
            "    Pullover       0.21      0.99      0.35      1000\n",
            "      Sandal       0.26      1.00      0.42      1000\n",
            "       Shirt       0.25      0.00      0.00      1000\n",
            "     Sneaker       0.00      0.00      0.00      1000\n",
            "     T-shirt       0.98      0.17      0.29      1000\n",
            "     Trouser       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.30     10000\n",
            "   macro avg       0.33      0.30      0.20     10000\n",
            "weighted avg       0.33      0.30      0.20     10000\n",
            "\n",
            "Classification report saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/classification_report.txt\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0    0    0    0    0 1000    0    0    0    0]\n",
            " [   0  199    0    2  110  689    0    0    0    0]\n",
            " [   0    0    0   16  979    5    0    0    0    0]\n",
            " [   0    0    0  672  318   10    0    0    0    0]\n",
            " [   0    0    0    1  995    3    1    0    0    0]\n",
            " [   0    0    0    0    0 1000    0    0    0    0]\n",
            " [   0    0    0   66  899   30    2    0    3    0]\n",
            " [   0    0    0    0    0 1000    0    0    0    0]\n",
            " [   0    0    0   71  718   34    5    0  172    0]\n",
            " [   0    0    0  345  648    7    0    0    0    0]]\n",
            "Confusion matrix saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/confusion_matrix.png\n",
            "Predictions saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "    --model_name EfficientNetB0 \\\n",
        "    --train_dir /content/RadImageNet/fashion_mnist_full_dataset/train \\\n",
        "    --test_dir /content/RadImageNet/fashion_mnist_full_dataset/test \\\n",
        "    --output_dir /content/RadImageNet/fashion_Eff_output \\\n",
        "    --lr 0.0001 \\\n",
        "    --batch_size 16 \\\n",
        "    --epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTTFzI3c5Tyt",
        "outputId": "f0bef749-ffbe-4c68-f24c-3c08f8aab03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-07 07:00:52.987094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762498853.038296    1931 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762498853.052325    1931 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762498853.107717    1931 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762498853.107757    1931 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762498853.107765    1931 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762498853.107772    1931 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-07 07:00:53.123724: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2.19.0\n",
            "Number of GPUs available: 1\n",
            "Loading training data paths and labels...\n",
            "DataLoader (train): Found categories in directory: ['Dress', 'Pullover', 'T-shirt', 'Shirt', 'Sandal', 'Coat', 'Ankle boot', 'Trouser', 'Sneaker', 'Bag']\n",
            "DataLoader (train): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/train/Dress\n",
            "DataLoader (train): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/train/Pullover\n",
            "DataLoader (train): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/T-shirt\n",
            "DataLoader (train): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/train/Shirt\n",
            "DataLoader (train): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/train/Sandal\n",
            "DataLoader (train): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/train/Coat\n",
            "DataLoader (train): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/train/Ankle boot\n",
            "DataLoader (train): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/train/Trouser\n",
            "DataLoader (train): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/train/Sneaker\n",
            "DataLoader (train): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/train/Bag\n",
            "DataLoader (train): Total images found: 60000\n",
            "DataLoader (train): Total labels found: 60000\n",
            "DataLoader (train): Number of unique labels after encoding: 10\n",
            "Training data: 60000 images, 10 classes\n",
            "Building Model ....\n",
            "I0000 00:00:1762498862.459542    1931 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "Training and cross-validating model...\n",
            "Training fold 1...\n",
            "Epoch 1/5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1762498877.562035    2012 service.cc:152] XLA service 0x7b71c80057f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1762498877.562081    2012 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-11-07 07:01:17.880823: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1762498879.609834    2012 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2025-11-07 07:01:26.674870: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:01:26.808944: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:01:27.122997: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:01:27.262623: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:01:27.955611: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:01:28.095102: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "I0000 00:00:1762498894.585558    2012 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m2497/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9044 - loss: 0.3742\n",
            "Epoch 1: val_loss improved from inf to 5.47253, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 23ms/step - accuracy: 0.9044 - loss: 0.3740 - val_accuracy: 0.2913 - val_loss: 5.4725 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2497/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9245 - loss: 0.3467\n",
            "Epoch 2: val_loss improved from 5.47253 to 2.84124, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - accuracy: 0.9245 - loss: 0.3464 - val_accuracy: 0.4638 - val_loss: 2.8412 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9428 - loss: 0.2088\n",
            "Epoch 3: val_loss improved from 2.84124 to 2.74079, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 21ms/step - accuracy: 0.9428 - loss: 0.2087 - val_accuracy: 0.5031 - val_loss: 2.7408 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2496/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9491 - loss: 0.1903\n",
            "Epoch 4: val_loss improved from 2.74079 to 2.47047, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 23ms/step - accuracy: 0.9491 - loss: 0.1902 - val_accuracy: 0.5461 - val_loss: 2.4705 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9483 - loss: 0.1780\n",
            "Epoch 5: val_loss improved from 2.47047 to 2.25016, saving model to /content/RadImageNet/fashion_Eff_output/models/model_1.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 23ms/step - accuracy: 0.9484 - loss: 0.1780 - val_accuracy: 0.5527 - val_loss: 2.2502 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "Time taken for fold 1: 308.604 seconds\n",
            "Training fold 2...\n",
            "Epoch 1/5\n",
            "\u001b[1m2497/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9511 - loss: 0.1733\n",
            "Epoch 1: val_loss improved from inf to 2.25732, saving model to /content/RadImageNet/fashion_Eff_output/models/model_2.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 21ms/step - accuracy: 0.9512 - loss: 0.1732 - val_accuracy: 0.5568 - val_loss: 2.2573 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2496/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9505 - loss: 0.1698\n",
            "Epoch 2: val_loss did not improve from 2.25732\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 23ms/step - accuracy: 0.9505 - loss: 0.1696 - val_accuracy: 0.5678 - val_loss: 2.2579 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2496/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9508 - loss: 0.1682\n",
            "Epoch 3: val_loss improved from 2.25732 to 2.18965, saving model to /content/RadImageNet/fashion_Eff_output/models/model_2.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 21ms/step - accuracy: 0.9508 - loss: 0.1681 - val_accuracy: 0.5689 - val_loss: 2.1897 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9539 - loss: 0.1559\n",
            "Epoch 4: val_loss improved from 2.18965 to 2.17910, saving model to /content/RadImageNet/fashion_Eff_output/models/model_2.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 23ms/step - accuracy: 0.9539 - loss: 0.1559 - val_accuracy: 0.5885 - val_loss: 2.1791 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2497/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9580 - loss: 0.1464\n",
            "Epoch 5: val_loss did not improve from 2.17910\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 23ms/step - accuracy: 0.9580 - loss: 0.1464 - val_accuracy: 0.5934 - val_loss: 2.2656 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "Time taken for fold 2: 304.379 seconds\n",
            "Training fold 3...\n",
            "Epoch 1/5\n",
            "\u001b[1m2495/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9556 - loss: 0.1587\n",
            "Epoch 1: val_loss improved from inf to 2.04383, saving model to /content/RadImageNet/fashion_Eff_output/models/model_3.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 23ms/step - accuracy: 0.9556 - loss: 0.1586 - val_accuracy: 0.5913 - val_loss: 2.0438 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m2498/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9532 - loss: 0.1699\n",
            "Epoch 2: val_loss improved from 2.04383 to 1.97776, saving model to /content/RadImageNet/fashion_Eff_output/models/model_3.weights.h5\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 20ms/step - accuracy: 0.9532 - loss: 0.1698 - val_accuracy: 0.5934 - val_loss: 1.9778 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m2499/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9552 - loss: 0.1524\n",
            "Epoch 3: val_loss did not improve from 1.97776\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 21ms/step - accuracy: 0.9552 - loss: 0.1524 - val_accuracy: 0.6080 - val_loss: 2.0026 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m2496/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9563 - loss: 0.1488\n",
            "Epoch 4: val_loss did not improve from 1.97776\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 23ms/step - accuracy: 0.9563 - loss: 0.1487 - val_accuracy: 0.6030 - val_loss: 2.0051 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m2495/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9537 - loss: 0.1603\n",
            "Epoch 5: val_loss did not improve from 1.97776\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 23ms/step - accuracy: 0.9537 - loss: 0.1602 - val_accuracy: 0.5939 - val_loss: 2.0758 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "Time taken for fold 3: 278.941 seconds\n",
            "Total training time for 3 folds: 891.924 seconds\n",
            "Training the model on the entire dataset...\n",
            "Epoch 1/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 15ms/step - accuracy: 0.9700 - loss: 0.1021\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 16ms/step - accuracy: 0.9718 - loss: 0.1018\n",
            "Epoch 3/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 16ms/step - accuracy: 0.9700 - loss: 0.1038\n",
            "Epoch 4/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 16ms/step - accuracy: 0.9728 - loss: 0.0966\n",
            "Epoch 5/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 15ms/step - accuracy: 0.9706 - loss: 0.1090\n",
            "Time taken to train on the entire dataset: 319.073 seconds\n",
            "Final training accuracy on the entire dataset: 98.162%\n",
            "Final training loss on the entire dataset: 0.067\n",
            "Final model weights saved at: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Cross-validation results - Mean Accuracy: 97.0%, Mean Loss: 0.107\n",
            "Loading test data paths and labels....\n",
            "DataLoader (test): Found categories: ['Dress', 'Pullover', 'T-shirt', 'Shirt', 'Sandal', 'Coat', 'Ankle boot', 'Trouser', 'Sneaker', 'Bag'] in /content/RadImageNet/fashion_mnist_full_dataset/test\n",
            "DataLoader (test): Processing category: Dress at /content/RadImageNet/fashion_mnist_full_dataset/test/Dress\n",
            "DataLoader (test): Processing category: Pullover at /content/RadImageNet/fashion_mnist_full_dataset/test/Pullover\n",
            "DataLoader (test): Processing category: T-shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/T-shirt\n",
            "DataLoader (test): Processing category: Shirt at /content/RadImageNet/fashion_mnist_full_dataset/test/Shirt\n",
            "DataLoader (test): Processing category: Sandal at /content/RadImageNet/fashion_mnist_full_dataset/test/Sandal\n",
            "DataLoader (test): Processing category: Coat at /content/RadImageNet/fashion_mnist_full_dataset/test/Coat\n",
            "DataLoader (test): Processing category: Ankle boot at /content/RadImageNet/fashion_mnist_full_dataset/test/Ankle boot\n",
            "DataLoader (test): Processing category: Trouser at /content/RadImageNet/fashion_mnist_full_dataset/test/Trouser\n",
            "DataLoader (test): Processing category: Sneaker at /content/RadImageNet/fashion_mnist_full_dataset/test/Sneaker\n",
            "DataLoader (test): Processing category: Bag at /content/RadImageNet/fashion_mnist_full_dataset/test/Bag\n",
            "DataLoader (test): Total images found: 10000\n",
            "DataLoader (test): Total labels found: 10000\n",
            "DataLoader (test): Number of unique labels after encoding: 10\n",
            "Test data: 10000 images, 10 classes\n",
            "Evaluating model on unseen test data...\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "Loaded model weights from: /content/RadImageNet/fashion_Eff_output/models/final_model.weights.h5\n",
            "Predicting on test data...\n",
            "2025-11-07 07:21:27.547956: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:21:27.681988: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:21:28.002999: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:21:28.144098: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:21:28.850740: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "2025-11-07 07:21:28.991805: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 38ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Ankle boot       0.94      0.36      0.52      1000\n",
            "         Bag       0.71      1.00      0.83      1000\n",
            "        Coat       0.32      0.87      0.46      1000\n",
            "       Dress       0.93      0.40      0.56      1000\n",
            "    Pullover       0.97      0.03      0.06      1000\n",
            "      Sandal       1.00      0.57      0.72      1000\n",
            "       Shirt       0.20      0.08      0.11      1000\n",
            "     Sneaker       0.51      1.00      0.67      1000\n",
            "     T-shirt       0.99      0.34      0.51      1000\n",
            "     Trouser       0.57      0.99      0.72      1000\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.71      0.56      0.52     10000\n",
            "weighted avg       0.71      0.56      0.52     10000\n",
            "\n",
            "Classification report saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/classification_report.txt\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 362    8    0    0    0    0    0  629    0    1]\n",
            " [   0 1000    0    0    0    0    0    0    0    0]\n",
            " [   0   63  866   20    0    0    0    0    0   51]\n",
            " [   0   27  126  398    1    0    7    0    4  437]\n",
            " [   0   65  848    0   30    0    4    0    0   53]\n",
            " [  23   69    0    0    0  567    0  341    0    0]\n",
            " [   0   85  741    4    0    0   77    0    1   92]\n",
            " [   0    4    0    0    0    0    0  996    0    0]\n",
            " [   0   77  163    2    0    0  289    1  343  125]\n",
            " [   0    3    0    2    0    0    0    0    0  995]]\n",
            "Confusion matrix saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/confusion_matrix.png\n",
            "Predictions saved to /content/RadImageNet/fashion_Eff_output/evaluation_results/predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8MohO2RKHXAz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}